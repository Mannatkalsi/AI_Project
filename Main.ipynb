{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 10%\n",
      "progress: 20%\n",
      "progress: 30%\n",
      "progress: 40%\n",
      "progress: 50%\n",
      "progress: 60%\n",
      "progress: 70%\n",
      "progress: 80%\n",
      "progress: 90%\n",
      "progress: 100%\n",
      "Step: 0 | Cumulative Reward: 0\n",
      "RENDERING...\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation:  0\n",
      "action:  1\n",
      "reward:  0\n",
      "Step: 1 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Down)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation:  1\n",
      "action:  3\n",
      "reward:  0.0\n",
      "Step: 2 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation:  0\n",
      "action:  1\n",
      "reward:  0.0\n",
      "Step: 3 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Down)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation:  1\n",
      "action:  3\n",
      "reward:  0.0\n",
      "Step: 4 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Up)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation:  1\n",
      "action:  3\n",
      "reward:  0.0\n",
      "Step: 5 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Up)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "observation:  2\n",
      "action:  0\n",
      "reward:  0.0\n",
      "Step: 6 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Left)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "observation:  6\n",
      "action:  1\n",
      "reward:  0.0\n",
      "Step: 7 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "observation:  10\n",
      "action:  2\n",
      "reward:  0.0\n",
      "Step: 8 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "observation:  14\n",
      "action:  1\n",
      "reward:  0.0\n",
      "Step: 9 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "observation:  14\n",
      "action:  1\n",
      "reward:  0.0\n",
      "Step: 10 | Cumulative Reward: 0.0\n",
      "RENDERING...\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "observation:  14\n",
      "action:  1\n",
      "reward:  0.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from src.driver import Driver\n",
    "from src.agents.random import Random\n",
    "from src.agents.qlearner import Qlearner\n",
    "from src.agents.tdlearner import TDlearner\n",
    "\n",
    "'''\n",
    "USAGE INSTRUCTIONS\n",
    "\n",
    "At the bottom of this file, these functions defining a combination of an agent\n",
    "and an environment are invoked. All but one are commented out. Choose which\n",
    "agent and environment you want to run, and uncomment that line. For example,\n",
    "to see the Qlearner agent operating the Taxi environment, uncomment:\n",
    "\n",
    "    #taxi_qlearner()\n",
    "\n",
    "It is recommended you leave all other function invocations commented out when\n",
    "you run this file, as it will be faster and you will only see the output you\n",
    "are interested in.\n",
    "'''\n",
    "\n",
    "def taxi_random():\n",
    "    agent = Random()\n",
    "    driver = Driver({\n",
    "        'epochs': 1000,\n",
    "        'env': gym.make('Taxi-v3'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_taxi_random()\n",
    "\n",
    "def taxi_qlearner():\n",
    "    agent = Qlearner({\n",
    "        'alpha': 0.1,\n",
    "        'gamma': 0.6,\n",
    "        'epsilon': 0.1,\n",
    "    })\n",
    "    driver = Driver({\n",
    "        'epochs': 10000,\n",
    "        'env': gym.make('Taxi-v3'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_taxi_qlearner()\n",
    "\n",
    "def cartpole_random():\n",
    "    agent = Random()\n",
    "    driver = Driver({\n",
    "        'epochs': 1000,\n",
    "        'env': gym.make('CartPole-v1'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_cartpole_random()\n",
    "\n",
    "def cartpole_qlearner():\n",
    "    agent = Qlearner({\n",
    "        'alpha': 0.2,\n",
    "        'gamma': 0.5,\n",
    "        'epsilon': 0.1,\n",
    "    })\n",
    "    driver = Driver({\n",
    "        'epochs': 50000,\n",
    "        'env': gym.make('CartPole-v1'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_cartpole_qlearner()\n",
    "\n",
    "def cartpole_tdlearner():\n",
    "    agent = TDlearner({\n",
    "        'alpha': 0.2,\n",
    "        'gamma': 0.5,\n",
    "        'epsilon': 0.1,\n",
    "    })\n",
    "    driver = Driver({\n",
    "        'epochs': 50000,\n",
    "        'env': gym.make('CartPole-v1'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_cartpole_tdlearner()\n",
    "\n",
    "def frozen_lake_random():\n",
    "    agent = Random()\n",
    "    driver = Driver({\n",
    "        'epochs': 1000,\n",
    "        'env': gym.make('FrozenLake-v0'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_frozen_lake_random()\n",
    "\n",
    "def frozen_lake_qlearner():\n",
    "    agent = Qlearner({\n",
    "        'alpha': 0.1,\n",
    "        'gamma': 0.6,\n",
    "        'epsilon': 0.3,\n",
    "    })\n",
    "    driver = Driver({\n",
    "        'epochs': 10000,\n",
    "        'env': gym.make('FrozenLake-v0'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_frozen_lake_qlearner()\n",
    "\n",
    "def frozen_lake_tdlearner():\n",
    "    agent = TDlearner({\n",
    "        'alpha': 0.1,\n",
    "        'gamma': 0.6,\n",
    "        'epsilon': 0.3,\n",
    "    })\n",
    "    driver = Driver({\n",
    "        'epochs': 10000,\n",
    "        'env': gym.make('FrozenLake-v0'),\n",
    "        'agent': agent,\n",
    "    })\n",
    "    driver.run_frozen_lake_tdlearner()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #taxi_random()\n",
    "    #taxi_qlearner()\n",
    "    #cartpole_random()\n",
    "    #cartpole_qlearner()\n",
    "    #cartpole_tdlearner()\n",
    "    #frozen_lake_random()\n",
    "    #frozen_lake_qlearner()\n",
    "    #frozen_lake_tdlearner()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
